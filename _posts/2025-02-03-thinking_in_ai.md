---
layout: post
title: 过去一年对 AI 的一些探索和思考
date: 2025-02-03 22:04:00 +0800
categories: ["ai"]
---

## 定义

什么是 llm，和 ai 是什么关系?

ai 的定义比较宽泛，而 llm（large language model 大语言模型） 是 ai 的一个子集，它指的是使用大量数据训练的，能够生成文本的模型。我们最近比较熟悉的 chatgpt、deepseek 就是典型的 llm 模型。其余的 ai 领域，包括自动驾驶等不在本文讨论范围内。

## 引言

过去一整年我的兴趣重心基本都在 llm 上, 一开始都是在了解和各种尝试不同平台提供的 llm，处于对这个技术的触碰和好奇阶段，主要是在探索 llm 的边界和可能性，希望可以了解：什么可以交给 llm 去做，什么不可以。这篇短文主要记录过去一年我对 llm 的一些探索、实践和思考。

我对 llm 的学习主要从两个方面由浅入深进行。
1. 底层基建：llm 是什么的一些思考
2. 上层应用：研究各种基于 llm 服务，构建起来的应用，主要是在思考 llm 如何解决具体的问题。

## 探索刚刚开始

在 2024 年的大部分时间内，llm 最出色的产品依然是 openai 的 chatgpt 系列。尽管过程有 claude 和国内不同大厂的追赶，openai 总是能够在大家都认为基本赶上后，发布一个新的版本和技术，继续拉开差距，例如 o1 推理模型。而最让我印象深刻的，是国内公司 deepseek 在 2024.12 到 2025.1 月的一系列开源模型发布，它利用极低的成本，在短时间内迅速追赶上 o1 的推理能力，并且开源了模型，让所有人都可以使用。

为什么一个不到 200 人的公司，可以短时间内迅速追赶上 o1 的推理能力？openai 可是有 1000 多人的团队，并且拥有无可比拟的算力资源。我想除了 deepseek 的工程师们有出色的工程能力外，更加客观的原因应该是现在人类还没有了解清楚 llm 的所有细节，甚至说人类还没有了解清楚智能是什么？

因此，llm 的探索才刚刚开始，就像就进了一片迷雾森林中，有的人员向正前方探索，例如 openai，它俨然有了伟大的收获。但openai 的方向就是唯一的方向，或者是最合理的方向吗？显然不是，deepseek 的研究员通过提出一些新的想法，开启了一个新的方向，结果找到了比 openai 更高效的工程方案以及获得几乎一致的推理能力，这个效率的提升进步了两个数量级。这就像各种聪明的人，踏进了一个金银岛一样，这是一个全新的领域，敢于前进和探索，总是有不同程度的收获。对比一些已经成熟的科研领域，更多的都是已经被探索完成，剩下的都是一些细枝末节的问题，现在 llm 的领域对科研人员来说是一个非常值得前进的领域。这也意味着未来的几年，llm 估计依然会有不同方向和不同程度的突破，作为一个技术同学，我非常期待，非常开心能够见证这些突破。

## 语言 + 逻辑 = 思考

chatgpt o1 和 deepseek r1 的推理能力，让我想起来了哲学家维特根斯坦的一些哲学观点。他是提出的 **图像理论**，认为语言通过逻辑结构和现实世界进行映射，因此我们可以通过语言向别人描述现实世界，介绍物体或描述事件。反过来，当我们无法向别人描述一个物体，证明我们并没有理解它，或者足够复杂的事物，语言可能无法直接描述它。正因为这样，苏格拉底说“对话和批判性思考才能检验真理和知识”，而维特根斯坦则说“不可言说的，我们需要保持沉默 （Woody one cannot speak, thereof one must be silent.）”。同时维特根斯坦早期的哲学思想，大致上认为 语言+逻辑 是人类思考和认识世界的工具。而具备推理能力的 llm 模型，可以看作是具备人类思考和认识世界的能力。

20世界中确实是大师辈出的时代，维特根斯坦提出了逻辑哲学论，香农提出了信息论，图灵则划定了计算的边界，并开始讨论机器是否可以思考的问题提出了图灵测试。这些问题随着算力、数据的发展，看起来终于会在这个时代进行汇合了。科学家们在被这些问题引导着前进，同时利用一个个的产品和实验来回答这些问题。我们终将能够清楚什么是人类的智能和思考，当这些技术再前进一个程度后，就会有新的一位哲学家对我们的成果进行描述。


上文我简单描述了一下关于 llm 的一些思考，我并不打算测评其中的一些模型，因为给出的结论没几个星期就过时了。接下来我简单描述一下我过去一年对 llm 的一些探索和实践。

## llm 使人更高效，但不会使人进步

很多人会期望 llm 能帮助自己做一些自己做不到的事情，例如提出新方法、新思路，让自己在工作和学习上有突破。非常遗憾，我认为 llm 是做不到的。llm 好比一个博学多才的学者，但假如你提的问题很肤浅，它也只能给你一些浅显的答案，就像一个小学生向一个大学老师提问一样。而人的高度往往决定他能够提出什么样的问题，就算一个人假装有深度地进行提问（即提出一个自己都不清楚的问题时），llm 就算回答一个正确的答案时，他自己也无法独立判断答案的对错，因此这个答案对他来说，是没有任何意义的。（这恰恰是 维特根斯坦 的哲学观点，不可言说的，我们需要保持沉默）

因此学习+实践+总结，依然是个人进步的唯一途径。好消息是，我们日常很多工作都可以交给 llm 去做，因此可以让我们有更多的时间去思考和学习，这提高了我们能够进步的概率。

## llm 是处理信息的工具，但处理的结果必须能够被验证

llm 是处理信息的工具，可以简单理解为一个黑盒。它能够接受信息，并根据要求，结合模型的参数，输出结果。假如 llm 的处理结果能够被验证，那么它就能够成为有效的工具。这里的被验证有多种方式，人类或者机器都可以。基于上面的论断，我利用 llm 设计了一个工具和一个使用范式，目前来看效果都还不错。

### 测试用例自动生成器

这个是观察了老婆的日常工作，发现其中的瓶颈在于分析代码和输出测试用例。因为最终的测试用例会被人工验证，因此 llm 是可以在其中进行加速的。最后花了大概两天的时间和老婆一起实现了构想，效率提高非常明显，她使用工具两周的工作产出，相当于她半年的产出。

### llm 编程范式

cursor 是一个非常优秀的编程工具，它能够根据代码的上下文，利用 llm 自动生成代码。但要真正让 llm 为编程助理，需要解决两个问题：
1. 代码的上下文如何被 llm 理解
2. llm 的输出结果如何被验证

问题 1 的解决方案是模块化设计，将代码拆分成多个模块，每个模块都是一个独立的单元，这样 llm 就可以仅仅需要分析小范围内的上下文，这有利于 llm 理解代码的意图和精准生成代码。

问题 2 的解决方案是基于模块化设计后，自动生成单元测试用例，人工确认单元测试的意图后，利用单元测试用例对 llm 的产出进行验证。因此工程师的主要工作是设计模块和接口，并确认单元测试的意图，而 llm 则负责生成代码。

事实上证明这个范式非常有效，**测试用例自动生成器** 作为个人项目，第一个版本只使用了 8 小时就完成基本的功能了，并带有相当高的单元测试覆盖率，这让我非常惊讶。

## 其他的应用

除了上面两个有实际效果的实践，还有一些是一直在生活和工作中在尝试的，例如在和老婆的讨论中，会使用 GET 笔记对讨论内容进行记录和整理；另外自己正在了解和学习 langChain 和 agent 相关的知识，正在构建一个基于 llm 的 TODO 应用来管理自己的一些日常计划。这些尝试都还在进行中，没有形成有效的产出，因此这里就不进行描述了。值得一提的是，不断地触碰 llm，这个过程让我感觉非常兴奋，同时也会刺激自己产出新的想法。

## 总结

llm 毫无疑问是近期最火热的议题，有的人认为它不过是一个统计模型，永远解决不了幻觉问题；有的人却过分夸大了它的能力，认为很快 llm 就会解决所有问题。首先我认为这 llm 是一个非常棒的工具，但它也仅仅是一个工具，和我们祖先学会取火一样。火焰让我们变得温暖，但不会让食物凭空出现。llm 的出现让我们能够从一些繁杂的信息处理问题中解放出来，当我们拥有了更多的闲暇和时间后，我们就可以思考更多的问题，那是一些更深远、更本质同时又更有价值的问题。